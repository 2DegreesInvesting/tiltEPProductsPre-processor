{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ee8ce93-0fe4-4a1b-ac06-f903e54430bc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 1. Typo correction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "abb4f705-b911-413b-a295-e17013c23f47",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 1.1 Import the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "922c33d3-4f90-4c1d-b25d-37955e860fc1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from langdetect import detect_langs, DetectorFactory\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "language_detector = pipeline(\"text-classification\", model=\"papluca/xlm-roberta-base-language-detection\") # this model is 1.1 gigabyte so it will take around 5 mins to download it\n",
    "translator = pipeline(\"text2text-generation\", model=\"oliverguhr/spelling-correction-english-base\", max_length=1000)\n",
    "\n",
    "DetectorFactory.seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "acfe9e88-a5c1-46f1-934e-f3075018fc49",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 1.2 Load in the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d3a5cf7-8184-4659-8799-18ac5e24cd85",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>products_and_services</th>\n",
       "      <th>products_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>industrial lifting</td>\n",
       "      <td>49affd7c-7f90-4977-8f10-ae84fe6b3dcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>customised lifting solutions</td>\n",
       "      <td>14961ecc-341b-48b0-bc70-a3db16e0972b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vacuum lifting solution</td>\n",
       "      <td>1d111749-f816-419e-b45f-06bbe291f9be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>concrete lifting solutions</td>\n",
       "      <td>c2986ffd-6fa6-4da0-94f2-b2da1c1d07e7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sheet metal handling</td>\n",
       "      <td>5720becf-9c80-485a-b0e4-97203117455b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20586</th>\n",
       "      <td>local public transport</td>\n",
       "      <td>38a4ec9f-9a2d-4628-99e5-7e8477571dd3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20587</th>\n",
       "      <td>passenger information</td>\n",
       "      <td>207854a8-a834-48a7-b397-294aed97ffb1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20588</th>\n",
       "      <td>rescue apparatus, hydraulic</td>\n",
       "      <td>dc1ff0ac-9e44-47cf-9981-009f600d9ee0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20589</th>\n",
       "      <td>wood pellets wood briquette</td>\n",
       "      <td>9e3e3cfe-27c2-4519-b364-8deaea7f6474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20590</th>\n",
       "      <td>wood briquette machines</td>\n",
       "      <td>cc310ec8-0f58-46f7-9768-040e9c103ad9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20591 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              products_and_services                           products_id\n",
       "0                industrial lifting  49affd7c-7f90-4977-8f10-ae84fe6b3dcc\n",
       "1      customised lifting solutions  14961ecc-341b-48b0-bc70-a3db16e0972b\n",
       "2           vacuum lifting solution  1d111749-f816-419e-b45f-06bbe291f9be\n",
       "3        concrete lifting solutions  c2986ffd-6fa6-4da0-94f2-b2da1c1d07e7\n",
       "4              sheet metal handling  5720becf-9c80-485a-b0e4-97203117455b\n",
       "...                             ...                                   ...\n",
       "20586        local public transport  38a4ec9f-9a2d-4628-99e5-7e8477571dd3\n",
       "20587         passenger information  207854a8-a834-48a7-b397-294aed97ffb1\n",
       "20588   rescue apparatus, hydraulic  dc1ff0ac-9e44-47cf-9981-009f600d9ee0\n",
       "20589   wood pellets wood briquette  9e3e3cfe-27c2-4519-b364-8deaea7f6474\n",
       "20590       wood briquette machines  cc310ec8-0f58-46f7-9768-040e9c103ad9\n",
       "\n",
       "[20591 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine the location of the dataframe containing the translated text\n",
    "base_tilt_data_location = \"../../data/example_data/input/tilt_base_products_and_services_unprocessed.csv\"\n",
    "\n",
    "# use raw_df\n",
    "base_tilt_data = pd.read_csv(base_tilt_data_location)\n",
    "\n",
    "# Display the dataframe\n",
    "display(base_tilt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tilt Italy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>products_and_services</th>\n",
       "      <th>products_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>persian blue salt</td>\n",
       "      <td>50abde66-58b7-4fb3-a007-1077fa41a010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>organic saffron bio</td>\n",
       "      <td>0ea739bc-c3fb-4476-b8d6-96ba5085aa00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rossoro</td>\n",
       "      <td>2b898f73-e699-4b52-926d-476b51dacd42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>peas</td>\n",
       "      <td>a7849fec-bf97-48b0-b89b-cb910a8d6dc8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cauliflowers</td>\n",
       "      <td>e09840c2-df4a-4920-b91b-e23177b5f5b3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3430</th>\n",
       "      <td>enamels</td>\n",
       "      <td>77890bab-e5c2-40d1-bcf7-f11fb9ac8c09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3431</th>\n",
       "      <td>breathable and mould resistant plastic coverings</td>\n",
       "      <td>d675d682-018e-4829-ac66-e61155d7a45e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3432</th>\n",
       "      <td>quartz paints</td>\n",
       "      <td>e5f78c8c-b79e-4a12-8451-867349f09cc6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3433</th>\n",
       "      <td>carpet</td>\n",
       "      <td>1f4814fc-759f-49b6-b2cc-9ba1c77582bd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>flame-resistant wallpaper</td>\n",
       "      <td>c2505123-a5fe-495f-b5ce-693feb1304f6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3435 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 products_and_services  \\\n",
       "0                                    persian blue salt   \n",
       "1                                  organic saffron bio   \n",
       "2                                              rossoro   \n",
       "3                                                 peas   \n",
       "4                                         cauliflowers   \n",
       "...                                                ...   \n",
       "3430                                           enamels   \n",
       "3431  breathable and mould resistant plastic coverings   \n",
       "3432                                     quartz paints   \n",
       "3433                                            carpet   \n",
       "3434                         flame-resistant wallpaper   \n",
       "\n",
       "                               products_id  \n",
       "0     50abde66-58b7-4fb3-a007-1077fa41a010  \n",
       "1     0ea739bc-c3fb-4476-b8d6-96ba5085aa00  \n",
       "2     2b898f73-e699-4b52-926d-476b51dacd42  \n",
       "3     a7849fec-bf97-48b0-b89b-cb910a8d6dc8  \n",
       "4     e09840c2-df4a-4920-b91b-e23177b5f5b3  \n",
       "...                                    ...  \n",
       "3430  77890bab-e5c2-40d1-bcf7-f11fb9ac8c09  \n",
       "3431  d675d682-018e-4829-ac66-e61155d7a45e  \n",
       "3432  e5f78c8c-b79e-4a12-8451-867349f09cc6  \n",
       "3433  1f4814fc-759f-49b6-b2cc-9ba1c77582bd  \n",
       "3434  c2505123-a5fe-495f-b5ce-693feb1304f6  \n",
       "\n",
       "[3435 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine the location of the dataframe containing the translated text\n",
    "italy_tilt_data_location = \"../../data/example_data/input/tilt_italy_products_and_services_unprocessed.csv\"\n",
    "\n",
    "# use raw_df\n",
    "italy_tilt_data = pd.read_csv(italy_tilt_data_location)\n",
    "\n",
    "# Display the dataframe\n",
    "display(italy_tilt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Apply typo correction module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_ld_detect_language(text, model=\"def\"):\n",
    "    \"\"\"Language detection wrapper.\n",
    "    \n",
    "    Returns detected language (ISO-code) and confidence of detection. In case of \n",
    "    failure of detection string 'ident_fail' and a pd.NA value for confidence is \n",
    "    returned.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The string for which language shall be detected.\n",
    "        model (str): The model to be used for language detection. Defaults to langdetect model.\n",
    "    Returns:\n",
    "        str: The detected language (ISO-code).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if model == \"def\":\n",
    "            highest_conf = detect_langs(text)[0]\n",
    "            return highest_conf.lang\n",
    "        else:\n",
    "            result = language_detector(text)[0]\n",
    "            return str(result[\"label\"])\n",
    "    except:   \n",
    "        return \"ident_fail\", pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typo_correction(text=\"\"):\n",
    "    \"\"\"Typo correction wrapper.\n",
    "    \n",
    "    Returns corrected text. In case of failure of correction the original text \n",
    "    is returned. \n",
    "    \n",
    "    Args:\n",
    "        text (str): The string to be corrected.\n",
    "    Returns:\n",
    "        str: The corrected string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # contextualspellcheck only works for english. the same applies to textblob and the huggingface pipeline. pyspellcheck does work with different languages but requires single words as input. (aka splitted)\n",
    "        return(TextBlob(text).correct().string)\n",
    "    except:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Typo correction module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typo_correct_df(df):\n",
    "    \"\"\"Typo correction wrapper for dataframes.\n",
    "    \n",
    "    Returns dataframe with corrected text. In case of failure of correction the \n",
    "    original text is returned. \n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing the text to be corrected.\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe with corrected text.\n",
    "    \"\"\"\n",
    "    #df['ID'] = range(1, len(df) + 1)\n",
    "    # detect the language of the text\n",
    "    print(\"Detecting the language of the text...\")\n",
    "    df.loc[:, \"language (ISO-code)\"] = df[\"products_and_services\"].progress_apply(lambda x: conf_ld_detect_language(x))\n",
    "\n",
    "    # then take subset of english texts\n",
    "    print(\"Taking subset of English texts...\")\n",
    "    english_df = df[df[\"language (ISO-code)\"] == \"en\"]\n",
    "    # exclude enlgish texts from the original df\n",
    "    df = df[df[\"language (ISO-code)\"] != \"en\"]\n",
    "\n",
    "    # apply typo correction to english texts\n",
    "    print(\"Applying typo correction...\")\n",
    "    english_df = english_df.copy()\n",
    "    english_df.loc[:, \"typo_corrected\"] = english_df[\"products_and_services\"].progress_apply(lambda x: typo_correction(x))\n",
    "\n",
    "    # merge the corrected english texts with the original df\n",
    "    print(\"Merging the corrected english texts with the original df...\")\n",
    "    df = pd.concat([df, english_df], ignore_index=True)\n",
    "    # replace empty values in typo_corrected with the original text\n",
    "    df[\"typo_corrected\"].fillna(df[\"products_and_services\"], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting the language of the text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20591/20591 [06:44<00:00, 50.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking subset of English texts...\n",
      "Applying typo correction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11380/11380 [32:36<00:00,  5.82it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging the corrected english texts with the original df...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_typo_corrected_df = typo_correct_df(base_tilt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tilt Italy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting the language of the text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3435/3435 [01:02<00:00, 54.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking subset of English texts...\n",
      "Applying typo correction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1932/1932 [05:26<00:00,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging the corrected english texts with the original df...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "italy_typo_corrected_df = typo_correct_df(italy_tilt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdc5767d-ddf9-4d7b-95e5-acf9a0100269",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 1.4 Export the dataframe with the corrected text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path for the new dataframe\n",
    "output_path_base_typo_corrected = \"../../data/example_data/output/base_data/base_typo_corrected_products.csv\"\n",
    "\n",
    "# Write the new dataframe to the path\n",
    "base_typo_corrected_df.to_csv(output_path_base_typo_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tilt Italy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1747a005-9c90-4934-8605-4b41d424916c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the path for the new dataframe\n",
    "output_path_italy_typo_corrected = \"../../data/example_data/output/italy_data/italy_typo_corrected_products.csv\"\n",
    "\n",
    "# Write the new dataframe to the path\n",
    "italy_typo_corrected_df.to_csv(output_path_italy_typo_corrected)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2. Typo_correction (Python solution)",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

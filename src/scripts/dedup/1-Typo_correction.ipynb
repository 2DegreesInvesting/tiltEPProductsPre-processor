{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ee8ce93-0fe4-4a1b-ac06-f903e54430bc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 1. Typo correction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "abb4f705-b911-413b-a295-e17013c23f47",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 1.1 Import the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "922c33d3-4f90-4c1d-b25d-37955e860fc1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from langdetect import detect_langs, DetectorFactory\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from transformers import pipeline\n",
    "from textblob import TextBlob\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "device = True if torch.cuda.is_available() else False\n",
    "print(\"GPU availability:{}\".format(device))\n",
    "\n",
    "language_detector = pipeline(\"text-classification\", model=\"papluca/xlm-roberta-base-language-detection\") # this model is 1.1 gigabyte so it will take around 5 mins to download it\n",
    "typo_corrector = pipeline(\"text2text-generation\", model=\"oliverguhr/spelling-correction-english-base\", max_length=1000)\n",
    "\n",
    "DetectorFactory.seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "acfe9e88-a5c1-46f1-934e-f3075018fc49",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 1.2 Load in the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d3a5cf7-8184-4659-8799-18ac5e24cd85",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if 'DATABRICKS_RUNTIME_VERSION' in os.environ:\n",
    "    # Determine the location of the dataframe containing the translated text\n",
    "    base_tilt_data_location = \"abfss://preprocessing@storagetiltdevelop.dfs.core.windows.net/data/example_data/output/base_data/base_flagged_products.csv\"\n",
    "    # Determine the location of the dataframe containing the translated text\n",
    "    italy_tilt_data_location = \"abfss://preprocessing@storagetiltdevelop.dfs.core.windows.net/data/example_data/output/italy_data/italy_flagged_products.csv\"\n",
    "\n",
    "    # use raw_df\n",
    "    base_tilt_data = spark.read.option(\"header\", \"true\").csv(base_tilt_data_location).toPandas()\n",
    "    # use raw_df\n",
    "    italy_tilt_data = spark.read.option(\"header\", \"true\").csv(italy_tilt_data_location).toPandas()\n",
    "else:\n",
    "    # Determine the location of the dataframe containing the translated text\n",
    "    base_tilt_data_location = \"../../data/example_data/output/base_data/base_flagged_products.csv\"\n",
    "    # Determine the location of the dataframe containing the translated text\n",
    "    italy_tilt_data_location = \"../../data/example_data/output/italy_data/italy_flagged_products.csv\"\n",
    "    \n",
    "    # use raw_df\n",
    "    base_tilt_data = pd.read_csv(base_tilt_data_location)\n",
    "    # use raw_df\n",
    "    italy_tilt_data = pd.read_csv(italy_tilt_data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Apply typo correction module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_ld_detect_language(text, model=\"def\"):\n",
    "    \"\"\"Language detection wrapper.\n",
    "    \n",
    "    Returns detected language (ISO-code) and confidence of detection. In case of \n",
    "    failure of detection string 'ident_fail' and a pd.NA value for confidence is \n",
    "    returned.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The string for which language shall be detected.\n",
    "        model (str): The model to be used for language detection. Defaults to langdetect model.\n",
    "    Returns:\n",
    "        str: The detected language (ISO-code).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if model == \"def\":\n",
    "            highest_conf = detect_langs(text)[0]\n",
    "            return highest_conf.lang\n",
    "        elif model == \"huggingface\":\n",
    "            result = language_detector(text)[0]\n",
    "            return str(result[\"label\"])\n",
    "    except:   \n",
    "        return \"ident_fail\", pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typo_correction(text=\"\", model=\"def\"):\n",
    "    \"\"\"Typo correction wrapper.\n",
    "    \n",
    "    Returns corrected text. In case of failure of correction the original text \n",
    "    is returned. \n",
    "    \n",
    "    Args:\n",
    "        text (str): The string to be corrected.\n",
    "        model (str): The model to be used for typo correction. Defaults to textblob model.\n",
    "    Returns:\n",
    "        str: The corrected string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if model == \"def\":\n",
    "            return(TextBlob(text).correct().string)\n",
    "        elif model == \"huggingface\":\n",
    "            return(typo_corrector(text)[0][\"generated_text\"])\n",
    "    except:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Typo correction module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typo_correct_df(df):\n",
    "    \"\"\"Typo correction wrapper for dataframes.\n",
    "    \n",
    "    Returns dataframe with corrected text. In case of failure of correction the \n",
    "    original text is returned. \n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing the text to be corrected.\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe with corrected text.\n",
    "    \"\"\"\n",
    "    # detect the language of the text but only for the rows that do not have a value in the automatic_processed_products_and_services column\n",
    "    print(\"Detecting the language of the text...\")\n",
    "    # only take rows that have a True value in the to_process column\n",
    "    to_process_df = df[df[\"to_process\"] == True].copy()\n",
    "    # exclude to_processed_df rows from df\n",
    "    df = df[df[\"to_process\"] == False].copy()\n",
    "    to_process_df.loc[:, \"language (ISO-code)\"] = to_process_df[\"products_and_services\"].progress_apply(lambda x: conf_ld_detect_language(x, model=\"huggingface\"))\n",
    "\n",
    "    # then take subset of english texts\n",
    "    print(\"Taking subset of English texts...\")\n",
    "    english_df = to_process_df[to_process_df[\"language (ISO-code)\"] == \"en\"]\n",
    "    # exclude enlgish texts from the original df\n",
    "    to_process_df = to_process_df[to_process_df[\"language (ISO-code)\"] != \"en\"]\n",
    "\n",
    "    # apply typo correction to english texts\n",
    "    print(\"Applying typo correction...\")\n",
    "    english_df = english_df.copy()\n",
    "    english_df.loc[:, \"typo_corrected\"] = english_df[\"products_and_services\"].progress_apply(lambda x: typo_correction(x, model=\"huggingface\"))\n",
    "\n",
    "    # merge the corrected english texts with the original df\n",
    "    print(\"Merging the corrected english texts with the original df...\")\n",
    "    df = pd.concat([to_process_df, english_df, df], ignore_index=True)\n",
    "    # replace empty values in typo_corrected with the original text\n",
    "    df[\"typo_corrected\"].fillna(df[\"products_and_services\"], inplace=True)\n",
    "    # make typo_corrected lowercase and remove all dots at the end\n",
    "    df[\"typo_corrected\"] = df[\"typo_corrected\"].str.lower().str.replace(\"\\.$\", \"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting the language of the text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14378 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14378/14378 [12:43<00:00, 18.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking subset of English texts...\n",
      "Applying typo correction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11522/11522 [1:08:48<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging the corrected english texts with the original df...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\selsabrouty\\AppData\\Local\\Temp\\ipykernel_5652\\1874215916.py:37: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[\"typo_corrected\"] = df[\"typo_corrected\"].str.lower().str.replace(\"\\.$\", \"\")\n"
     ]
    }
   ],
   "source": [
    "base_typo_corrected_df = typo_correct_df(base_tilt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tilt Italy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting the language of the text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 838/838 [00:34<00:00, 24.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking subset of English texts...\n",
      "Applying typo correction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 609/609 [03:12<00:00,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging the corrected english texts with the original df...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\selsabrouty\\AppData\\Local\\Temp\\ipykernel_5652\\1874215916.py:37: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[\"typo_corrected\"] = df[\"typo_corrected\"].str.lower().str.replace(\"\\.$\", \"\")\n"
     ]
    }
   ],
   "source": [
    "italy_typo_corrected_df = typo_correct_df(italy_tilt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdc5767d-ddf9-4d7b-95e5-acf9a0100269",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 1.4 Export the dataframe with the corrected text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'DATABRICKS_RUNTIME_VERSION' in os.environ:\n",
    "    # Define the path for the new dataframe\n",
    "    output_path_base_typo_corrected = \"abfss://preprocessing@storagetiltdevelop.dfs.core.windows.net/data/example_data/output/base_data/base_typo_corrected_products.csv\"\n",
    "    # Define the path for the new dataframe\n",
    "    output_path_italy_typo_corrected = \"abfss://preprocessing@storagetiltdevelop.dfs.core.windows.net/data/example_data/output/italy_data/italy_typo_corrected_products.csv\"\n",
    "\n",
    "    # Convert the pandas dataframe to a spark sql dataframe\n",
    "    base_typo_corrected_spark = spark.createDataFrame(base_typo_corrected_df)\n",
    "    # Convert the pandas dataframe to a spark sql dataframe\n",
    "    italy_typo_corrected_spark = spark.createDataFrame(italy_typo_corrected_df)\n",
    "\n",
    "    # Write the new dataframe to the path\n",
    "    base_typo_corrected_spark.write.csv(output_path_base_typo_corrected, mode=\"overwrite\", header=True)\n",
    "    # Write the new dataframe to the path\n",
    "    italy_typo_corrected_spark.write.csv(output_path_italy_typo_corrected, mode=\"overwrite\", header=True)\n",
    "else:\n",
    "    # Define the path for the new dataframe\n",
    "    output_path_base_typo_corrected = \"../../data/example_data/output/base_data/base_typo_corrected_products.csv\"\n",
    "    # Define the path for the new dataframe\n",
    "    output_path_italy_typo_corrected = \"../../data/example_data/output/italy_data/italy_typo_corrected_products.csv\"\n",
    "\n",
    "    # Write the new dataframe to the path\n",
    "    base_typo_corrected_df.to_csv(output_path_base_typo_corrected, index=False)\n",
    "    # Write the new dataframe to the path\n",
    "    italy_typo_corrected_df.to_csv(output_path_italy_typo_corrected, index=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2. Typo_correction (Python solution)",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

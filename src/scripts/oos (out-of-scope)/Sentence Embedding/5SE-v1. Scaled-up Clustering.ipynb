{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import math\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from collections import defaultdict\n",
    "from joblib import Parallel, delayed\n",
    "from funcy import log_durations\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>products_id</th>\n",
       "      <th>products_and_services</th>\n",
       "      <th>clustered_id</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>164399edbf8e880dc2e856f50d51e720bd0a8abe</td>\n",
       "      <td>fish, frozen and deep-frozen</td>\n",
       "      <td>a18df3877d3f9598d7c8fbae0adc2cad4acf37c6</td>\n",
       "      <td>fish frozen deepfrozen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b0d3c55743b1b858ec2843c8870116bb8af543fd</td>\n",
       "      <td>drilling and test boring - equipment</td>\n",
       "      <td>49659f8efe8d9a92455f0d378783469558ae7df1</td>\n",
       "      <td>drilling test boring equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b14c038972e6a52bfbf3ffbe77def57a62c5b9cf</td>\n",
       "      <td>well-management services</td>\n",
       "      <td>b14c038972e6a52bfbf3ffbe77def57a62c5b9cf</td>\n",
       "      <td>wellmanagement service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abadc2542b4b5c1ecfe41c22afb2347b1d9b65af</td>\n",
       "      <td>electronic data processing - software</td>\n",
       "      <td>35596a3df5495e2dc5d18cff45c58cadda91040c</td>\n",
       "      <td>electronic data processing software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60c58ad2ef34d96fae028f1039fab03dec9eb9a2</td>\n",
       "      <td>communication</td>\n",
       "      <td>60c58ad2ef34d96fae028f1039fab03dec9eb9a2</td>\n",
       "      <td>communication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31541</th>\n",
       "      <td>a56bfdd9971ddba76de33e5dd394faab63d2c58c</td>\n",
       "      <td>trading in non-ferrous products</td>\n",
       "      <td>5af4a5f264253d48a9504c6e9e9de651f5528121</td>\n",
       "      <td>trading nonferrous product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31542</th>\n",
       "      <td>d16685f9db86a7e446d5a4c763a17016ffdfa613</td>\n",
       "      <td>precision weights for scales</td>\n",
       "      <td>b52520ccdfafa1b05949ffe08c0fdde9e2556a9e</td>\n",
       "      <td>precision weight scale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31543</th>\n",
       "      <td>37c8e6d302d907a76f49d45a91949c86dd5fcc03</td>\n",
       "      <td>weights and masses - measurement and verificat...</td>\n",
       "      <td>822c0e12996351ae9cf05354936d074bb4c6103b</td>\n",
       "      <td>weight mass measurement verification instrument</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31544</th>\n",
       "      <td>4aa756effa61af41058cf80f475a03b439232cfe</td>\n",
       "      <td>manicure scissors</td>\n",
       "      <td>4aa756effa61af41058cf80f475a03b439232cfe</td>\n",
       "      <td>manicure scissors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31545</th>\n",
       "      <td>c732592a40981d7bd20a41585672204b41f93b12</td>\n",
       "      <td>mozzarella for pizza</td>\n",
       "      <td>c732592a40981d7bd20a41585672204b41f93b12</td>\n",
       "      <td>mozzarella pizza</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31546 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    products_id  \\\n",
       "0      164399edbf8e880dc2e856f50d51e720bd0a8abe   \n",
       "1      b0d3c55743b1b858ec2843c8870116bb8af543fd   \n",
       "2      b14c038972e6a52bfbf3ffbe77def57a62c5b9cf   \n",
       "3      abadc2542b4b5c1ecfe41c22afb2347b1d9b65af   \n",
       "4      60c58ad2ef34d96fae028f1039fab03dec9eb9a2   \n",
       "...                                         ...   \n",
       "31541  a56bfdd9971ddba76de33e5dd394faab63d2c58c   \n",
       "31542  d16685f9db86a7e446d5a4c763a17016ffdfa613   \n",
       "31543  37c8e6d302d907a76f49d45a91949c86dd5fcc03   \n",
       "31544  4aa756effa61af41058cf80f475a03b439232cfe   \n",
       "31545  c732592a40981d7bd20a41585672204b41f93b12   \n",
       "\n",
       "                                   products_and_services  \\\n",
       "0                           fish, frozen and deep-frozen   \n",
       "1                   drilling and test boring - equipment   \n",
       "2                               well-management services   \n",
       "3                  electronic data processing - software   \n",
       "4                                          communication   \n",
       "...                                                  ...   \n",
       "31541                    trading in non-ferrous products   \n",
       "31542                       precision weights for scales   \n",
       "31543  weights and masses - measurement and verificat...   \n",
       "31544                                  manicure scissors   \n",
       "31545                               mozzarella for pizza   \n",
       "\n",
       "                                   clustered_id  \\\n",
       "0      a18df3877d3f9598d7c8fbae0adc2cad4acf37c6   \n",
       "1      49659f8efe8d9a92455f0d378783469558ae7df1   \n",
       "2      b14c038972e6a52bfbf3ffbe77def57a62c5b9cf   \n",
       "3      35596a3df5495e2dc5d18cff45c58cadda91040c   \n",
       "4      60c58ad2ef34d96fae028f1039fab03dec9eb9a2   \n",
       "...                                         ...   \n",
       "31541  5af4a5f264253d48a9504c6e9e9de651f5528121   \n",
       "31542  b52520ccdfafa1b05949ffe08c0fdde9e2556a9e   \n",
       "31543  822c0e12996351ae9cf05354936d074bb4c6103b   \n",
       "31544  4aa756effa61af41058cf80f475a03b439232cfe   \n",
       "31545  c732592a40981d7bd20a41585672204b41f93b12   \n",
       "\n",
       "                                          cleaned_text  \n",
       "0                               fish frozen deepfrozen  \n",
       "1                       drilling test boring equipment  \n",
       "2                               wellmanagement service  \n",
       "3                  electronic data processing software  \n",
       "4                                        communication  \n",
       "...                                                ...  \n",
       "31541                       trading nonferrous product  \n",
       "31542                           precision weight scale  \n",
       "31543  weight mass measurement verification instrument  \n",
       "31544                                manicure scissors  \n",
       "31545                                 mozzarella pizza  \n",
       "\n",
       "[31546 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine the location of the dataframe containing the typo-corrected text\n",
    "file_location = \"../data/example_data/output/cleaned_products.parquet\"\n",
    "\n",
    "# Read the dataframe\n",
    "df  = pd.read_parquet(file_location)\n",
    "\n",
    "# Display dataframe\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding data\n",
      "Model loaded\n",
      "Unique sentences 30841\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b10904f4b7347c3ae5ef17534953646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/241 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Embedding data')\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print('Model loaded')\n",
    "\n",
    "sentences = df['cleaned_text'].tolist()\n",
    "unique_sentences = df['cleaned_text'].unique()\n",
    "print('Unique sentences', len(unique_sentences))\n",
    "\n",
    "sentences = df['cleaned_text'].tolist()\n",
    "unique_sentences = df['cleaned_text'].unique()\n",
    "embeddings = model.encode(unique_sentences, show_progress_bar=True, batch_size=128)\n",
    "\n",
    "mapping = {sentence: embedding for sentence, embedding in zip(unique_sentences, embeddings)}\n",
    "embeddings = np.array([mapping[sentence] for sentence in sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04650404,  0.00217801, -0.02107469, ..., -0.02285529,\n",
       "        -0.00280993,  0.05536779],\n",
       "       [-0.04808221, -0.0097314 ,  0.01712464, ...,  0.00614742,\n",
       "        -0.01118629, -0.07062028],\n",
       "       [-0.06738088,  0.04993471,  0.0725988 , ...,  0.00713424,\n",
       "         0.01262637, -0.03323374],\n",
       "       ...,\n",
       "       [-0.04802645,  0.07145448, -0.047667  , ..., -0.04117569,\n",
       "        -0.02189348, -0.05587696],\n",
       "       [-0.04348597,  0.0291066 , -0.01997651, ...,  0.00454498,\n",
       "         0.00567288,  0.01318082],\n",
       "       [-0.10508741,  0.02357166, -0.04046485, ...,  0.02065877,\n",
       "         0.10108754, -0.06006776]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_data(data, key='text', model_name='all-MiniLM-L6-v2', cores=1, gpu=False, batch_size=128):\n",
    "    \"\"\"\n",
    "    Embed the sentences/text using the MiniLM language model (which uses mean pooling)\n",
    "    \"\"\"\n",
    "    print('Embedding data')\n",
    "    model = SentenceTransformer(model_name)\n",
    "    print('Model loaded')\n",
    "\n",
    "    sentences = data[key].tolist()\n",
    "    unique_sentences = data[key].unique()\n",
    "    print('Unique sentences', len(unique_sentences))\n",
    "\n",
    "    if cores == 1:\n",
    "        embeddings = model.encode(unique_sentences, show_progress_bar=True, batch_size=batch_size, convert_to_tensor=True)\n",
    "    else:\n",
    "        devices = ['cpu'] * cores\n",
    "        if gpu:\n",
    "            devices = None  # use all CUDA devices\n",
    "\n",
    "        # Start the multi-process pool on multiple devices\n",
    "        print('Multi-process pool starting')\n",
    "        pool = model.start_multi_process_pool(devices)\n",
    "        print('Multi-process pool started')\n",
    "\n",
    "        chunk_size = math.ceil(len(unique_sentences) / cores)\n",
    "\n",
    "        # Compute the embeddings using the multi-process pool\n",
    "        embeddings = model.encode_multi_process(unique_sentences, pool, batch_size=batch_size, chunk_size=chunk_size)\n",
    "        model.stop_multi_process_pool(pool)\n",
    "\n",
    "    print(\"Embeddings computed\")\n",
    "    mapping = {sentence: embedding for sentence, embedding in zip(unique_sentences, embeddings)}\n",
    "    embeddings = np.array([mapping[sentence] for sentence in sentences])\n",
    "  \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a: Tensor, b: Tensor):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n",
    "    :return: Matrix with res[i][j]  = cos_sim(a[i], b[j])\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(a, torch.Tensor):\n",
    "        a = torch.tensor(np.array(a))\n",
    "\n",
    "    if not isinstance(b, torch.Tensor):\n",
    "        b = torch.tensor(np.array(b))\n",
    "    \n",
    "    if len(a.shape) == 1:\n",
    "        a = a.unsqueeze(0)\n",
    "\n",
    "    if len(b.shape) == 1:\n",
    "        b = b.unsqueeze(0)\n",
    "\n",
    "    a_norm = torch.nn.functional.normalize(a, p=2, dim=1)\n",
    "    b_norm = torch.nn.functional.normalize(b, p=2, dim=1)\n",
    "    return torch.mm(a_norm, b_norm.transpose(0, 1))\n",
    "\n",
    "\n",
    "def get_embeddings(ids, embeddings):\n",
    "    return np.array([embeddings[idx] for idx in ids])\n",
    "\n",
    "\n",
    "def reorder_and_filter_cluster(\n",
    "    cluster_idx, cluster, cluster_embeddings, cluster_head_embedding, threshold\n",
    "):\n",
    "    cos_scores = cos_sim(cluster_head_embedding, cluster_embeddings)\n",
    "    sorted_vals, indices = torch.sort(cos_scores[0], descending=True)\n",
    "    bigger_than_threshold = sorted_vals > threshold\n",
    "    indices = indices[bigger_than_threshold]\n",
    "    sorted_vals = sorted_vals.numpy()\n",
    "    return cluster_idx, [(cluster[i][0], sorted_vals[i]) for i in indices]\n",
    "\n",
    "\n",
    "def get_ids(cluster):\n",
    "    return [transaction[0] for transaction in cluster]\n",
    "\n",
    "\n",
    "def reorder_and_filter_clusters(clusters, embeddings, threshold, parallel):\n",
    "    results = parallel(\n",
    "        delayed(reorder_and_filter_cluster)(\n",
    "            cluster_idx,\n",
    "            cluster,\n",
    "            get_embeddings(get_ids(cluster), embeddings),\n",
    "            get_embeddings([cluster_idx], embeddings),\n",
    "            threshold,\n",
    "        )\n",
    "        for cluster_idx, cluster in tqdm(clusters.items())\n",
    "    )\n",
    "\n",
    "    clusters = {k: v for k, v in results}\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def get_embeddings(ids, embeddings):\n",
    "    return np.array([embeddings[idx] for idx in ids])\n",
    "\n",
    "\n",
    "def get_clustured_ids(clusters):\n",
    "    clustered_ids = set(\n",
    "        [transaction[0] for cluster in clusters.values() for transaction in cluster]\n",
    "    )\n",
    "    clustered_ids |= set(clusters.keys())\n",
    "    return clustered_ids\n",
    "\n",
    "\n",
    "def get_clusters_ids(clusters):\n",
    "    return list(clusters.keys())\n",
    "\n",
    "\n",
    "def get_unclustured_ids(ids, clusters):\n",
    "    clustered_ids = get_clustured_ids(clusters)\n",
    "    unclustered_ids = list(set(ids) - clustered_ids)\n",
    "    return unclustered_ids\n",
    "\n",
    "\n",
    "def sort_clusters(clusters):\n",
    "    return dict(\n",
    "        sorted(clusters.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "    )  # sort based on size\n",
    "\n",
    "\n",
    "def sort_cluster(cluster):\n",
    "    return list(\n",
    "        sorted(cluster, key=lambda x: x[1], reverse=True)\n",
    "    )  # sort based on similarity\n",
    "\n",
    "\n",
    "def filter_clusters(clusters, min_cluster_size):\n",
    "    return {k: v for k, v in clusters.items() if len(v) >= min_cluster_size}\n",
    "\n",
    "\n",
    "def unique(collection):\n",
    "    return list(dict.fromkeys(collection))\n",
    "\n",
    "\n",
    "def unique_txs(collection):\n",
    "    seen = set()\n",
    "    return [x for x in collection if not (x[0] in seen or seen.add(x[0]))]\n",
    "\n",
    "\n",
    "\n",
    "def chunk(txs, chunk_size):\n",
    "    n = math.ceil(len(txs) / chunk_size)\n",
    "    k, m = divmod(len(txs), n)\n",
    "    return (txs[i * k + min(i, m) : (i + 1) * k + min(i + 1, m)] for i in range(n))\n",
    "\n",
    "\n",
    "\n",
    "def online_community_detection(\n",
    "    ids,\n",
    "    embeddings,\n",
    "    clusters=None,\n",
    "    threshold=0.7,\n",
    "    min_cluster_size=3,\n",
    "    chunk_size=2500,\n",
    "    iterations=10,\n",
    "    cores=1,\n",
    "):\n",
    "    if clusters is None:\n",
    "        clusters = {}\n",
    "\n",
    "    with Parallel(n_jobs=cores) as parallel:\n",
    "        for iteration in range(iterations):\n",
    "            print(\"1. Nearest cluster\")\n",
    "            unclustered_ids = get_unclustured_ids(ids, clusters)\n",
    "            cluster_ids = list(clusters.keys())\n",
    "            print(\"Unclustured\", len(unclustered_ids))\n",
    "            print(\"Clusters\", len(cluster_ids))\n",
    "            clusters = nearest_cluster(\n",
    "                unclustered_ids,\n",
    "                embeddings,\n",
    "                clusters,\n",
    "                chunk_size=chunk_size,\n",
    "                parallel=parallel,\n",
    "            )\n",
    "            print(\"\\n\\n\")\n",
    "\n",
    "            print(\"2. Create new clusters\")\n",
    "            unclustered_ids = get_unclustured_ids(ids, clusters)\n",
    "            print(\"Unclustured\", len(unclustered_ids))\n",
    "            new_clusters = create_clusters(\n",
    "                unclustered_ids,\n",
    "                embeddings,\n",
    "                clusters={},\n",
    "                min_cluster_size=3,\n",
    "                chunk_size=chunk_size,\n",
    "                threshold=threshold,\n",
    "                parallel=parallel,\n",
    "            )\n",
    "            new_cluster_ids = list(new_clusters.keys())\n",
    "            print(\"\\n\\n\")\n",
    "\n",
    "            print(\"3. Merge new clusters\", len(new_cluster_ids))\n",
    "            max_clusters_size = 25000\n",
    "            while True:\n",
    "                new_cluster_ids = list(new_clusters.keys())\n",
    "                old_new_cluster_ids = new_cluster_ids\n",
    "                new_clusters = create_clusters(\n",
    "                    new_cluster_ids,\n",
    "                    embeddings,\n",
    "                    new_clusters,\n",
    "                    min_cluster_size=1,\n",
    "                    chunk_size=max_clusters_size,\n",
    "                    threshold=threshold,\n",
    "                    parallel=parallel,\n",
    "                )\n",
    "                new_clusters = filter_clusters(new_clusters, 2)\n",
    "\n",
    "                new_cluster_ids = list(new_clusters.keys())\n",
    "                print(\"New merged clusters\", len(new_cluster_ids))\n",
    "                if len(old_new_cluster_ids) < max_clusters_size:\n",
    "                    break\n",
    "\n",
    "            new_clusters = filter_clusters(new_clusters, min_cluster_size)\n",
    "            print(\n",
    "                f\"New clusters with min community size >= {min_cluster_size}\",\n",
    "                len(new_clusters),\n",
    "            )\n",
    "            clusters = {**new_clusters, **clusters}\n",
    "            print(\"Total clusters\", len(clusters))\n",
    "            clusters = sort_clusters(clusters)\n",
    "            print(\"\\n\\n\")\n",
    "\n",
    "            print(\"4. Nearest cluster\")\n",
    "            unclustered_ids = get_unclustured_ids(ids, clusters)\n",
    "            cluster_ids = list(clusters.keys())\n",
    "            print(\"Unclustured\", len(unclustered_ids))\n",
    "            print(\"Clusters\", len(cluster_ids))\n",
    "            clusters = nearest_cluster(\n",
    "                unclustered_ids,\n",
    "                embeddings,\n",
    "                clusters,\n",
    "                chunk_size=chunk_size,\n",
    "                parallel=parallel,\n",
    "            )\n",
    "            clusters = sort_clusters(clusters)\n",
    "\n",
    "            unclustered_ids = get_unclustured_ids(ids, clusters)\n",
    "            clustured_ids = get_clustured_ids(clusters)\n",
    "            print(\"Clustured\", len(clustured_ids))\n",
    "            print(\"Unclustured\", len(unclustered_ids))\n",
    "            print(\n",
    "                f\"Percentage clustured {len(clustured_ids) / (len(clustured_ids) + len(unclustered_ids)) * 100:.2f}%\"\n",
    "            )\n",
    "\n",
    "            print(\"\\n\\n\")\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def get_ids(cluster):\n",
    "    return [transaction[0] for transaction in cluster]\n",
    "\n",
    "\n",
    "def nearest_cluster_chunk(\n",
    "    chunk_ids, chunk_embeddings, cluster_ids, cluster_embeddings, threshold\n",
    "):\n",
    "    cos_scores = cos_sim(chunk_embeddings, cluster_embeddings)\n",
    "    top_val_large, top_idx_large = cos_scores.topk(k=1, largest=True)\n",
    "    top_idx_large = top_idx_large[:, 0].tolist()\n",
    "    top_val_large = top_val_large[:, 0].tolist()\n",
    "    cluster_assignment = []\n",
    "    for i, (score, idx) in enumerate(zip(top_val_large, top_idx_large)):\n",
    "        cluster_id = cluster_ids[idx]\n",
    "        if score < threshold:\n",
    "            cluster_id = None\n",
    "        cluster_assignment.append(((chunk_ids[i], score), cluster_id))\n",
    "    return cluster_assignment\n",
    "\n",
    "\n",
    "def nearest_cluster(\n",
    "    transaction_ids,\n",
    "    embeddings,\n",
    "    clusters=None,\n",
    "    parallel=None,\n",
    "    threshold=0.75,\n",
    "    chunk_size=2500,\n",
    "):\n",
    "    cluster_ids = list(clusters.keys())\n",
    "    if len(cluster_ids) == 0:\n",
    "        return clusters\n",
    "    cluster_embeddings = get_embeddings(cluster_ids, embeddings)\n",
    "\n",
    "    c = list(chunk(transaction_ids, chunk_size))\n",
    "\n",
    "    with log_durations(logging.info, \"Parallel jobs nearest cluster\"):\n",
    "        out = parallel(\n",
    "            delayed(nearest_cluster_chunk)(\n",
    "                chunk_ids,\n",
    "                get_embeddings(chunk_ids, embeddings),\n",
    "                cluster_ids,\n",
    "                cluster_embeddings,\n",
    "                threshold,\n",
    "            )\n",
    "            for chunk_ids in tqdm(c)\n",
    "        )\n",
    "        cluster_assignment = [assignment for sublist in out for assignment in sublist]\n",
    "\n",
    "    for (transaction_id, similarity), cluster_id in cluster_assignment:\n",
    "        if cluster_id is None:\n",
    "            continue\n",
    "        clusters[cluster_id].append(\n",
    "            (transaction_id, similarity)\n",
    "        )  # TODO sort in right order\n",
    "\n",
    "    clusters = {\n",
    "        cluster_id: unique_txs(sort_cluster(cluster))\n",
    "        for cluster_id, cluster in clusters.items()\n",
    "    }  # Sort based on similarity\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def create_clusters(\n",
    "    ids,\n",
    "    embeddings,\n",
    "    clusters=None,\n",
    "    parallel=None,\n",
    "    min_cluster_size=3,\n",
    "    threshold=0.75,\n",
    "    chunk_size=2500,\n",
    "):\n",
    "    to_cluster_ids = np.array(ids)\n",
    "    np.random.shuffle(\n",
    "        to_cluster_ids\n",
    "    )  # TODO evaluate performance without, try sorted list\n",
    "\n",
    "    c = list(chunk(to_cluster_ids, chunk_size))\n",
    "\n",
    "    with log_durations(logging.info, \"Parallel jobs create clusters\"):\n",
    "        out = parallel(\n",
    "            delayed(fast_clustering)(\n",
    "                chunk_ids,\n",
    "                get_embeddings(chunk_ids, embeddings),\n",
    "                threshold,\n",
    "                min_cluster_size,\n",
    "            )\n",
    "            for chunk_ids in tqdm(c)\n",
    "        )\n",
    "\n",
    "    # Combine output\n",
    "    new_clusters = {}\n",
    "    for out_clusters in out:\n",
    "        for idx, cluster in out_clusters.items():\n",
    "            # new_clusters[idx] = unique([(idx, 1)] + new_clusters.get(idx, []) + cluster)\n",
    "            new_clusters[idx] = unique_txs(cluster + new_clusters.get(idx, []))\n",
    "\n",
    "    # Add ids from old cluster to new cluster\n",
    "    for cluster_idx, cluster in new_clusters.items():\n",
    "        community_extended = []\n",
    "        for (idx, similarity) in cluster:\n",
    "            community_extended += [(idx, similarity)] + clusters.get(idx, [])\n",
    "        new_clusters[cluster_idx] = unique_txs(community_extended)\n",
    "\n",
    "    new_clusters = reorder_and_filter_clusters(\n",
    "        new_clusters, embeddings, threshold, parallel\n",
    "    )  # filter to keep only the relevant\n",
    "    new_clusters = sort_clusters(new_clusters)\n",
    "\n",
    "    clustered_ids = set()\n",
    "    for idx, cluster_ids in new_clusters.items():\n",
    "        filtered = set(cluster_ids) - clustered_ids\n",
    "        cluster_ids = [\n",
    "            cluster_idx for cluster_idx in cluster_ids if cluster_idx in filtered\n",
    "        ]\n",
    "        new_clusters[idx] = cluster_ids\n",
    "        clustered_ids |= set(cluster_ids)\n",
    "\n",
    "    new_clusters = filter_clusters(new_clusters, min_cluster_size)\n",
    "    new_clusters = sort_clusters(new_clusters)\n",
    "    return new_clusters\n",
    "\n",
    "\n",
    "def fast_clustering(ids, embeddings, threshold=0.70, min_cluster_size=10):\n",
    "    \"\"\"\n",
    "    Function for Fast Clustering\n",
    "\n",
    "    Finds in the embeddings all communities, i.e. embeddings that are close (closer than threshold).\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute cosine similarity scores\n",
    "    cos_scores = cos_sim(embeddings, embeddings)\n",
    "\n",
    "    # Step 1) Create clusters where similarity is bigger than threshold\n",
    "    bigger_than_threshold = cos_scores >= threshold\n",
    "    indices = bigger_than_threshold.nonzero()\n",
    "\n",
    "    cos_scores = cos_scores.numpy()\n",
    "\n",
    "    extracted_clusters = defaultdict(lambda: [])\n",
    "    for row, col in indices.tolist():\n",
    "        extracted_clusters[ids[row]].append((ids[col], cos_scores[row, col]))\n",
    "\n",
    "    extracted_clusters = sort_clusters(extracted_clusters)  # FIXME\n",
    "\n",
    "    # Step 2) Remove overlapping clusters\n",
    "    unique_clusters = {}\n",
    "    extracted_ids = set()\n",
    "\n",
    "    for cluster_id, cluster in extracted_clusters.items():\n",
    "        add_cluster = True\n",
    "        for transaction in cluster:\n",
    "            if transaction[0] in extracted_ids:\n",
    "                add_cluster = False\n",
    "                break\n",
    "\n",
    "        if add_cluster:\n",
    "            unique_clusters[cluster_id] = cluster\n",
    "            for transaction in cluster:\n",
    "                extracted_ids.add(transaction[0])\n",
    "\n",
    "    new_clusters = {}\n",
    "    for cluster_id, cluster in unique_clusters.items():\n",
    "        community_extended = []\n",
    "        for idx in cluster:\n",
    "            community_extended.append(idx)\n",
    "        new_clusters[cluster_id] = unique_txs(community_extended)\n",
    "\n",
    "    new_clusters = filter_clusters(new_clusters, min_cluster_size)\n",
    "\n",
    "    return new_clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df.products_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding data\n",
      "Model loaded\n",
      "Unique sentences 31546\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44341fe0c1f450daaa744fbeef7dc46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/247 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings computed\n"
     ]
    }
   ],
   "source": [
    "embeddings = embed_data(df, 'products_and_services', cores=1)\n",
    "embeddings = {idx: embedding for idx, embedding in zip(ids, embeddings)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Nearest cluster\n",
      "Unclustured 31546\n",
      "Clusters 0\n",
      "\n",
      "\n",
      "\n",
      "2. Create new clusters\n",
      "Unclustured 31546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  5.74it/s]\n",
      "100%|██████████| 1845/1845 [00:00<00:00, 2842.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "3. Merge new clusters 1845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.41it/s]\n",
      "100%|██████████| 791/791 [00:00<00:00, 2601.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New merged clusters 791\n",
      "New clusters with min community size >= 3 791\n",
      "Total clusters 791\n",
      "\n",
      "\n",
      "\n",
      "4. Nearest cluster\n",
      "Unclustured 25588\n",
      "Clusters 791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 20.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustured 8102\n",
      "Unclustured 23444\n",
      "Percentage clustured 25.68%\n",
      "\n",
      "\n",
      "\n",
      "1. Nearest cluster\n",
      "Unclustured 23444\n",
      "Clusters 791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 18.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "2. Create new clusters\n",
      "Unclustured 23444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  5.21it/s]\n",
      "100%|██████████| 943/943 [00:00<00:00, 3207.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "3. Merge new clusters 943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 55.56it/s]\n",
      "100%|██████████| 664/664 [00:00<00:00, 2801.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New merged clusters 664\n",
      "New clusters with min community size >= 3 664\n",
      "Total clusters 1455\n",
      "\n",
      "\n",
      "\n",
      "4. Nearest cluster\n",
      "Unclustured 20393\n",
      "Clusters 1455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 22.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustured 12079\n",
      "Unclustured 19467\n",
      "Percentage clustured 38.29%\n",
      "\n",
      "\n",
      "\n",
      "1. Nearest cluster\n",
      "Unclustured 19467\n",
      "Clusters 1455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 16.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "2. Create new clusters\n",
      "Unclustured 19467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.92it/s]\n",
      "100%|██████████| 552/552 [00:00<00:00, 3305.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "3. Merge new clusters 552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n",
      "100%|██████████| 505/505 [00:00<00:00, 3175.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New merged clusters 505\n",
      "New clusters with min community size >= 3 505\n",
      "Total clusters 1960\n",
      "\n",
      "\n",
      "\n",
      "4. Nearest cluster\n",
      "Unclustured 17669\n",
      "Clusters 1960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 14.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustured 14306\n",
      "Unclustured 17240\n",
      "Percentage clustured 45.35%\n",
      "\n",
      "\n",
      "\n",
      "1. Nearest cluster\n",
      "Unclustured 17240\n",
      "Clusters 1960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "2. Create new clusters\n",
      "Unclustured 17240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.46it/s]\n",
      "100%|██████████| 250/250 [00:00<00:00, 3246.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "3. Merge new clusters 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 166.56it/s]\n",
      "100%|██████████| 247/247 [00:00<00:00, 3207.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New merged clusters 247\n",
      "New clusters with min community size >= 3 247\n",
      "Total clusters 2207\n",
      "\n",
      "\n",
      "\n",
      "4. Nearest cluster\n",
      "Unclustured 16453\n",
      "Clusters 2207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 14.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustured 15240\n",
      "Unclustured 16306\n",
      "Percentage clustured 48.31%\n",
      "\n",
      "\n",
      "\n",
      "1. Nearest cluster\n",
      "Unclustured 16306\n",
      "Clusters 2207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 15.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "2. Create new clusters\n",
      "Unclustured 16306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  7.71it/s]\n",
      "100%|██████████| 170/170 [00:00<00:00, 3207.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "3. Merge new clusters 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 250.15it/s]\n",
      "100%|██████████| 170/170 [00:00<00:00, 2881.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New merged clusters 170\n",
      "New clusters with min community size >= 3 170\n",
      "Total clusters 2377\n",
      "\n",
      "\n",
      "\n",
      "4. Nearest cluster\n",
      "Unclustured 15773\n",
      "Clusters 2377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  9.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustured 15845\n",
      "Unclustured 15701\n",
      "Percentage clustured 50.23%\n",
      "\n",
      "\n",
      "\n",
      "1. Nearest cluster\n",
      "Unclustured 15701\n",
      "Clusters 2377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 14.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "2. Create new clusters\n",
      "Unclustured 15701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  8.16it/s]\n",
      "100%|██████████| 157/157 [00:00<00:00, 3018.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "3. Merge new clusters 157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 250.11it/s]\n",
      "100%|██████████| 157/157 [00:00<00:00, 2343.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New merged clusters 157\n",
      "New clusters with min community size >= 3 157\n",
      "Total clusters 2534\n",
      "\n",
      "\n",
      "\n",
      "4. Nearest cluster\n",
      "Unclustured 15220\n",
      "Clusters 2534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 14.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustured 16370\n",
      "Unclustured 15176\n",
      "Percentage clustured 51.89%\n",
      "\n",
      "\n",
      "\n",
      "1. Nearest cluster\n",
      "Unclustured 15176\n",
      "Clusters 2534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 14.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "2. Create new clusters\n",
      "Unclustured 15176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  6.98it/s]\n",
      "100%|██████████| 96/96 [00:00<00:00, 3096.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "3. Merge new clusters 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 124.99it/s]\n",
      "100%|██████████| 96/96 [00:00<00:00, 2823.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New merged clusters 96\n",
      "New clusters with min community size >= 3 96\n",
      "Total clusters 2630\n",
      "\n",
      "\n",
      "\n",
      "4. Nearest cluster\n",
      "Unclustured 14881\n",
      "Clusters 2630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustured 16703\n",
      "Unclustured 14843\n",
      "Percentage clustured 52.95%\n",
      "\n",
      "\n",
      "\n",
      "1. Nearest cluster\n",
      "Unclustured 14843\n",
      "Clusters 2630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "2. Create new clusters\n",
      "Unclustured 14843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  5.67it/s]\n",
      "100%|██████████| 146/146 [00:00<00:00, 2979.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "3. Merge new clusters 146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 333.15it/s]\n",
      "100%|██████████| 145/145 [00:00<00:00, 2958.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New merged clusters 145\n",
      "New clusters with min community size >= 3 145\n",
      "Total clusters 2775\n",
      "\n",
      "\n",
      "\n",
      "4. Nearest cluster\n",
      "Unclustured 14395\n",
      "Clusters 2775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustured 17185\n",
      "Unclustured 14361\n",
      "Percentage clustured 54.48%\n",
      "\n",
      "\n",
      "\n",
      "1. Nearest cluster\n",
      "Unclustured 14361\n",
      "Clusters 2775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "2. Create new clusters\n",
      "Unclustured 14361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  4.74it/s]\n",
      "100%|██████████| 83/83 [00:00<00:00, 3073.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "3. Merge new clusters 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 166.70it/s]\n",
      "100%|██████████| 83/83 [00:00<00:00, 3073.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New merged clusters 83\n",
      "New clusters with min community size >= 3 83\n",
      "Total clusters 2858\n",
      "\n",
      "\n",
      "\n",
      "4. Nearest cluster\n",
      "Unclustured 14107\n",
      "Clusters 2858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustured 17454\n",
      "Unclustured 14092\n",
      "Percentage clustured 55.33%\n",
      "\n",
      "\n",
      "\n",
      "1. Nearest cluster\n",
      "Unclustured 14092\n",
      "Clusters 2858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "2. Create new clusters\n",
      "Unclustured 14092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  6.52it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 3111.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "3. Merge new clusters 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 333.46it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 2624.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New merged clusters 84\n",
      "New clusters with min community size >= 3 84\n",
      "Total clusters 2942\n",
      "\n",
      "\n",
      "\n",
      "4. Nearest cluster\n",
      "Unclustured 13836\n",
      "Clusters 2942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustured 17719\n",
      "Unclustured 13827\n",
      "Percentage clustured 56.17%\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clusters = online_community_detection(ids, embeddings, clusters, chunk_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cluster in enumerate(clusters):\n",
    "    for product_id in clusters[cluster]:\n",
    "        df.loc[df[\"products_id\"].str.contains(product_id[0]),\"cluster_id\"] = int(i)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = df[df['cluster_id'].notnull()].products_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1166907"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette_score([embeddings[x] for x in indices.iloc[:]],df.loc[df['cluster_id'].notnull(), 'cluster_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>products_id</th>\n",
       "      <th>clustered_id_x</th>\n",
       "      <th>products_and_services</th>\n",
       "      <th>clustered_id_y</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>predicted_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0184628897818527ff8610ee5e277c042d54bd78</td>\n",
       "      <td>0184628897818527ff8610ee5e277c042d54bd78</td>\n",
       "      <td>magnetic platens</td>\n",
       "      <td>0184628897818527ff8610ee5e277c042d54bd78</td>\n",
       "      <td>magnetic platen</td>\n",
       "      <td>2120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b5da318747baea08381c0f76f43061621540c5f8</td>\n",
       "      <td>b5da318747baea08381c0f76f43061621540c5f8</td>\n",
       "      <td>platens</td>\n",
       "      <td>b5da318747baea08381c0f76f43061621540c5f8</td>\n",
       "      <td>platen</td>\n",
       "      <td>2120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>319a82778e111a5231977d8c56dcaeff867a2f8f</td>\n",
       "      <td>d5c69d047908660c5b1360d5f22c3a87d410ded6</td>\n",
       "      <td>data loggers</td>\n",
       "      <td>d5c69d047908660c5b1360d5f22c3a87d410ded6</td>\n",
       "      <td>data logger</td>\n",
       "      <td>2145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92fb45ad67b286563d7630ea1b20776c1b136046</td>\n",
       "      <td>d5c69d047908660c5b1360d5f22c3a87d410ded6</td>\n",
       "      <td>data-loggers</td>\n",
       "      <td>d5c69d047908660c5b1360d5f22c3a87d410ded6</td>\n",
       "      <td>dataloggers</td>\n",
       "      <td>2145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e029962abf3d76f83e3c80e11db5699136e09854</td>\n",
       "      <td>e029962abf3d76f83e3c80e11db5699136e09854</td>\n",
       "      <td>data logger recorders</td>\n",
       "      <td>e029962abf3d76f83e3c80e11db5699136e09854</td>\n",
       "      <td>data logger recorder</td>\n",
       "      <td>2145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17714</th>\n",
       "      <td>71576cb159bee5ed36bdec2f240e74b75f60b18e</td>\n",
       "      <td>da626fbdee5dc2c14e1f294fde700571dfb78c0b</td>\n",
       "      <td>air-conditioning systems, vehicles</td>\n",
       "      <td>da626fbdee5dc2c14e1f294fde700571dfb78c0b</td>\n",
       "      <td>airconditioning system vehicle</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17715</th>\n",
       "      <td>c5d893093bc7070c63c19110a4fc0e4a265031ca</td>\n",
       "      <td>c5d893093bc7070c63c19110a4fc0e4a265031ca</td>\n",
       "      <td>air conditioning systems for building</td>\n",
       "      <td>c5d893093bc7070c63c19110a4fc0e4a265031ca</td>\n",
       "      <td>air conditioning system building</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17716</th>\n",
       "      <td>8dd049875009bb697ad73f715bfa881b5b664bcc</td>\n",
       "      <td>c5d893093bc7070c63c19110a4fc0e4a265031ca</td>\n",
       "      <td>air conditioning and ventilation systems for b...</td>\n",
       "      <td>c5d893093bc7070c63c19110a4fc0e4a265031ca</td>\n",
       "      <td>air conditioning ventilation system building</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17717</th>\n",
       "      <td>a7bada8d0c2c93f0e80c8ab2226ba7394ff45ff8</td>\n",
       "      <td>38c28b8fbe87a29272225385b1f2b0295e8288fc</td>\n",
       "      <td>cnc turned plastic parts</td>\n",
       "      <td>38c28b8fbe87a29272225385b1f2b0295e8288fc</td>\n",
       "      <td>cnc turned plastic part</td>\n",
       "      <td>1115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17718</th>\n",
       "      <td>a286363727b21526cd3b3a89c6ff9b5f182fc1d1</td>\n",
       "      <td>38c28b8fbe87a29272225385b1f2b0295e8288fc</td>\n",
       "      <td>plastic cnc turned parts</td>\n",
       "      <td>38c28b8fbe87a29272225385b1f2b0295e8288fc</td>\n",
       "      <td>plastic cnc turned part</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17719 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    products_id  \\\n",
       "0      0184628897818527ff8610ee5e277c042d54bd78   \n",
       "1      b5da318747baea08381c0f76f43061621540c5f8   \n",
       "2      319a82778e111a5231977d8c56dcaeff867a2f8f   \n",
       "3      92fb45ad67b286563d7630ea1b20776c1b136046   \n",
       "4      e029962abf3d76f83e3c80e11db5699136e09854   \n",
       "...                                         ...   \n",
       "17714  71576cb159bee5ed36bdec2f240e74b75f60b18e   \n",
       "17715  c5d893093bc7070c63c19110a4fc0e4a265031ca   \n",
       "17716  8dd049875009bb697ad73f715bfa881b5b664bcc   \n",
       "17717  a7bada8d0c2c93f0e80c8ab2226ba7394ff45ff8   \n",
       "17718  a286363727b21526cd3b3a89c6ff9b5f182fc1d1   \n",
       "\n",
       "                                 clustered_id_x  \\\n",
       "0      0184628897818527ff8610ee5e277c042d54bd78   \n",
       "1      b5da318747baea08381c0f76f43061621540c5f8   \n",
       "2      d5c69d047908660c5b1360d5f22c3a87d410ded6   \n",
       "3      d5c69d047908660c5b1360d5f22c3a87d410ded6   \n",
       "4      e029962abf3d76f83e3c80e11db5699136e09854   \n",
       "...                                         ...   \n",
       "17714  da626fbdee5dc2c14e1f294fde700571dfb78c0b   \n",
       "17715  c5d893093bc7070c63c19110a4fc0e4a265031ca   \n",
       "17716  c5d893093bc7070c63c19110a4fc0e4a265031ca   \n",
       "17717  38c28b8fbe87a29272225385b1f2b0295e8288fc   \n",
       "17718  38c28b8fbe87a29272225385b1f2b0295e8288fc   \n",
       "\n",
       "                                   products_and_services  \\\n",
       "0                                       magnetic platens   \n",
       "1                                                platens   \n",
       "2                                           data loggers   \n",
       "3                                           data-loggers   \n",
       "4                                  data logger recorders   \n",
       "...                                                  ...   \n",
       "17714                 air-conditioning systems, vehicles   \n",
       "17715              air conditioning systems for building   \n",
       "17716  air conditioning and ventilation systems for b...   \n",
       "17717                           cnc turned plastic parts   \n",
       "17718                           plastic cnc turned parts   \n",
       "\n",
       "                                 clustered_id_y  \\\n",
       "0      0184628897818527ff8610ee5e277c042d54bd78   \n",
       "1      b5da318747baea08381c0f76f43061621540c5f8   \n",
       "2      d5c69d047908660c5b1360d5f22c3a87d410ded6   \n",
       "3      d5c69d047908660c5b1360d5f22c3a87d410ded6   \n",
       "4      e029962abf3d76f83e3c80e11db5699136e09854   \n",
       "...                                         ...   \n",
       "17714  da626fbdee5dc2c14e1f294fde700571dfb78c0b   \n",
       "17715  c5d893093bc7070c63c19110a4fc0e4a265031ca   \n",
       "17716  c5d893093bc7070c63c19110a4fc0e4a265031ca   \n",
       "17717  38c28b8fbe87a29272225385b1f2b0295e8288fc   \n",
       "17718  38c28b8fbe87a29272225385b1f2b0295e8288fc   \n",
       "\n",
       "                                       cleaned_text  predicted_cluster  \n",
       "0                                   magnetic platen             2120.0  \n",
       "1                                            platen             2120.0  \n",
       "2                                       data logger             2145.0  \n",
       "3                                       dataloggers             2145.0  \n",
       "4                              data logger recorder             2145.0  \n",
       "...                                             ...                ...  \n",
       "17714                airconditioning system vehicle               42.0  \n",
       "17715              air conditioning system building               42.0  \n",
       "17716  air conditioning ventilation system building               42.0  \n",
       "17717                       cnc turned plastic part             1115.0  \n",
       "17718                       plastic cnc turned part               68.0  \n",
       "\n",
       "[17719 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[df['cluster_id'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>products_id</th>\n",
       "      <th>products_and_services</th>\n",
       "      <th>clustered_id</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cluster_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>15ea1aa6b5579a4524c4e1b6fc255993ba43336c</td>\n",
       "      <td>welding work - steels and metal</td>\n",
       "      <td>21e4006d4ebaddc61e70dc1108bd4a82bfdb4cd1</td>\n",
       "      <td>welding work steel metal</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>20ffa4c9bae74888ad3c7929e7037b1c9ec204ca</td>\n",
       "      <td>robotised welding</td>\n",
       "      <td>20ffa4c9bae74888ad3c7929e7037b1c9ec204ca</td>\n",
       "      <td>robotised welding</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>055453216d6334f7018a1b6302a23bca4e682203</td>\n",
       "      <td>welding, plastics - machinery</td>\n",
       "      <td>9268d0b2eeaa712fbcf9304a3c1bca5213428a4d</td>\n",
       "      <td>welding plastic machinery</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>e1f0f79e4d4076a66868349d634cc5cf69bdd1d7</td>\n",
       "      <td>mechanized welding</td>\n",
       "      <td>e1f0f79e4d4076a66868349d634cc5cf69bdd1d7</td>\n",
       "      <td>mechanized welding</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>b06f16e1a0318eaf4bfe21901587c20badf74ddd</td>\n",
       "      <td>iron welding</td>\n",
       "      <td>b06f16e1a0318eaf4bfe21901587c20badf74ddd</td>\n",
       "      <td>iron welding</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29359</th>\n",
       "      <td>37db9e2fbc522a86217e46e86bdbfc7d5966d198</td>\n",
       "      <td>gas welding - equipment and supplies</td>\n",
       "      <td>0d71ff724ce0306736dc85f0b844814a6dd11ad0</td>\n",
       "      <td>gas welding equipment supply</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29360</th>\n",
       "      <td>282383bdb9038a6780c0c2a3911c02e427c1b0fb</td>\n",
       "      <td>welding gases</td>\n",
       "      <td>282383bdb9038a6780c0c2a3911c02e427c1b0fb</td>\n",
       "      <td>welding gas</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29821</th>\n",
       "      <td>5c7cbd9e41a08cd75001c7906d9c1f416cdf8ef2</td>\n",
       "      <td>supplies for welding</td>\n",
       "      <td>bb3c3fc23a71b902a0e891183f9126862cea49e9</td>\n",
       "      <td>supply welding</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30480</th>\n",
       "      <td>1434bc30c8413149af64043dc803ff3e703d86a4</td>\n",
       "      <td>welding plastic materials</td>\n",
       "      <td>1434bc30c8413149af64043dc803ff3e703d86a4</td>\n",
       "      <td>welding plastic material</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31497</th>\n",
       "      <td>d63a16f4f6232764f37407f09a8c259e54253df0</td>\n",
       "      <td>friction welding</td>\n",
       "      <td>d63a16f4f6232764f37407f09a8c259e54253df0</td>\n",
       "      <td>friction welding</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    products_id  \\\n",
       "94     15ea1aa6b5579a4524c4e1b6fc255993ba43336c   \n",
       "359    20ffa4c9bae74888ad3c7929e7037b1c9ec204ca   \n",
       "465    055453216d6334f7018a1b6302a23bca4e682203   \n",
       "1462   e1f0f79e4d4076a66868349d634cc5cf69bdd1d7   \n",
       "1705   b06f16e1a0318eaf4bfe21901587c20badf74ddd   \n",
       "...                                         ...   \n",
       "29359  37db9e2fbc522a86217e46e86bdbfc7d5966d198   \n",
       "29360  282383bdb9038a6780c0c2a3911c02e427c1b0fb   \n",
       "29821  5c7cbd9e41a08cd75001c7906d9c1f416cdf8ef2   \n",
       "30480  1434bc30c8413149af64043dc803ff3e703d86a4   \n",
       "31497  d63a16f4f6232764f37407f09a8c259e54253df0   \n",
       "\n",
       "                      products_and_services  \\\n",
       "94          welding work - steels and metal   \n",
       "359                       robotised welding   \n",
       "465           welding, plastics - machinery   \n",
       "1462                     mechanized welding   \n",
       "1705                           iron welding   \n",
       "...                                     ...   \n",
       "29359  gas welding - equipment and supplies   \n",
       "29360                         welding gases   \n",
       "29821                  supplies for welding   \n",
       "30480             welding plastic materials   \n",
       "31497                      friction welding   \n",
       "\n",
       "                                   clustered_id                  cleaned_text  \\\n",
       "94     21e4006d4ebaddc61e70dc1108bd4a82bfdb4cd1      welding work steel metal   \n",
       "359    20ffa4c9bae74888ad3c7929e7037b1c9ec204ca             robotised welding   \n",
       "465    9268d0b2eeaa712fbcf9304a3c1bca5213428a4d     welding plastic machinery   \n",
       "1462   e1f0f79e4d4076a66868349d634cc5cf69bdd1d7            mechanized welding   \n",
       "1705   b06f16e1a0318eaf4bfe21901587c20badf74ddd                  iron welding   \n",
       "...                                         ...                           ...   \n",
       "29359  0d71ff724ce0306736dc85f0b844814a6dd11ad0  gas welding equipment supply   \n",
       "29360  282383bdb9038a6780c0c2a3911c02e427c1b0fb                   welding gas   \n",
       "29821  bb3c3fc23a71b902a0e891183f9126862cea49e9                supply welding   \n",
       "30480  1434bc30c8413149af64043dc803ff3e703d86a4      welding plastic material   \n",
       "31497  d63a16f4f6232764f37407f09a8c259e54253df0              friction welding   \n",
       "\n",
       "       cluster_id  \n",
       "94            1.0  \n",
       "359           1.0  \n",
       "465           1.0  \n",
       "1462          1.0  \n",
       "1705          1.0  \n",
       "...           ...  \n",
       "29359         1.0  \n",
       "29360         1.0  \n",
       "29821         1.0  \n",
       "30480         1.0  \n",
       "31497         1.0  \n",
       "\n",
       "[102 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get rows where cluster_id value is equal to 1\n",
    "x[x['cluster_id'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = df[df['cluster_id'].notnull()].rename(columns={\"clustered_id\": \"truth_cluster\", \"cluster_id\": \"predicted_cluster\"})\n",
    "ari = np.round(adjusted_rand_score(complete_df[\"truth_cluster\"].values, complete_df[\"predicted_cluster\"].values), 3)\n",
    "nmi = np.round(normalized_mutual_info_score(complete_df[\"truth_cluster\"].values, complete_df[\"predicted_cluster\"].values), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ari' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mari\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ari' is not defined"
     ]
    }
   ],
   "source": [
    "ari"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
